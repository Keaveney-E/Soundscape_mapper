{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAVPskZXqLji3ipv/jg6KG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keaveney-E/Soundscape_mapper/blob/main/Soundscape_Mapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outline\n",
        "\n",
        "The package soundscape_mapper is an open-source Python toolbox that utilizes non-negative matrix factorization (NMF) in audio source separation. This is a quick start guide for the application of soundscape_mapper in acoustic analysis. For more information, please visit our Github.\n",
        "\n",
        "This guide contains four sections:\n",
        "\n",
        "Audio visualization\n",
        "Model training\n",
        "Deployment and spectrogram reconstruction\n",
        "Sound source visualisation"
      ],
      "metadata": {
        "id": "aMHUIhIMHHKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation\n",
        "Dependancies:\n",
        "\n",
        "Python>=3.7\n",
        "\n",
        "numpy==1.21.6\n",
        "\n",
        "pandas==1.3.5\n",
        "\n",
        "audioread==2.1.9\n",
        "\n",
        "librosa==0.8.1\n",
        "\n",
        "scikit-learn==1.0.2\n",
        "\n",
        "scipy==1.7.3\n",
        "\n",
        "matplotlib==3.2.2\n",
        "\n",
        "plotly==5.5.0\n",
        "\n",
        "To install soundscape_mapper, clone the repository in your Python environment."
      ],
      "metadata": {
        "id": "XvEoWbeiDF76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone soundscape_mapper from GitHub @Keaveney-e-org\n",
        "git clone https://github.com/keaveney-e-org/soundscape_mapper.git"
      ],
      "metadata": {
        "id": "BukkCMVkEqqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, install the requirements.txt in the package folder for installing required packages."
      ],
      "metadata": {
        "id": "_HVleibxFB7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "cd soundscape_mapper\n",
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "3FPNph2GFGqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick start"
      ],
      "metadata": {
        "id": "cMM2Y-BBFXm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio Visualisation\n",
        "\n",
        "soundscape_mapper provides a function audio_visualization to transform an audio into a spectrogram on the hertz or mel scale. It also enables the use of Welchâ€™s averaging method and spectrogram prewhitening in noise reduction. This example uses a short audio clip of dolphin and seal calls to demonstrate the ecoacoustic application of source separation."
      ],
      "metadata": {
        "id": "eo6SCLehGP8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soundscape_mapper.soundscape_viewer import audio_visualization\n",
        "# Define spectrogram parameters\n",
        "sound_train = audio_visualization(filename='copelands_w2019.wav', path='./data/wav/', offset_read=0, duration_read=15,\n",
        "                                  FFT_size=512, time_resolution=0.1, prewhiten_percent=10, f_range=[0,8000])"
      ],
      "metadata": {
        "id": "Ftfb1bKiH0tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Model Training\n",
        "\n",
        "After preparing the training spectrogram, we can train a model with source_separation. NMF learns a set of basis functions to reconstruct the training spectrogram. In soundscape_mapper, we can apply PC-NMF to separate the basis functions into two groups according to their source-specific periodicity. In this example, one group of basis funcitons is associated with dolphin call (mainly < 10 kHz) and another group is associated with noise (mainly > 3.5 kHz). Save the model for further applications."
      ],
      "metadata": {
        "id": "d_h-3AfEIKAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soundscape_mapper.soundscape_viewer import source_separation\n",
        "\n",
        "# Define model parameters\n",
        "model=source_separation(feature_length=30, basis_num=10)\n",
        "\n",
        "# Feature learning\n",
        "model.learn_feature(input_data=copelands_w2019.data, f=copelands_w2019.f, method='PCNMF')\n",
        "\n",
        "# Plot the basis functions of two sound source\n",
        "model.plot_nmf(plot_type='W', source=1)\n",
        "model.plot_nmf(plot_type='W', source=2)\n",
        "\n",
        "# Save the model\n",
        "model.save_model(filename='./data/model/wind_model.mat')"
      ],
      "metadata": {
        "id": "tj29VfvaFY9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Deployment and spectrogram reconstruction"
      ],
      "metadata": {
        "id": "ryY2mhxcJB1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate another spectrogram for testing the source separation model."
      ],
      "metadata": {
        "id": "ODrqkMsTJDZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a spectrogram\n",
        "sound_predict=audio_visualization(filename='copelands_w2019.wav', path='./data/wav/', offset_read=30, duration_read=15,\n",
        "                                    FFT_size=512, time_resolution=0.1, prewhiten_percent=10, f_range=[0,8000])"
      ],
      "metadata": {
        "id": "9qhDzMf3JNTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the saved model and perform source separation. After the prediction procedure, plot the reconstructed spectrograms to evaluate the separation of deer calls and noise."
      ],
      "metadata": {
        "id": "tCzWpcXxJqyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy the model\n",
        "model=source_separation()\n",
        "model.load_model(filename='./data/model/wind_model.mat')\n",
        "model.prediction(input_data=sound_predict.data, f=sound_predict.f)\n",
        "\n",
        "# View individual reconstructed spectrogram\n",
        "model.plot_nmf(plot_type = 'separation', source = 1)\n",
        "model.plot_nmf(plot_type = 'separation', source = 2)"
      ],
      "metadata": {
        "id": "L2GUZLgCJwt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Presence detection"
      ],
      "metadata": {
        "id": "BnrNAXWGKBfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the reconstructed spectrogram, we can use the function spectrogram_detection to detect the presence of target signals (e.g., dolphin calls, peaks in wind-driven ambient noise ect..). This function will generate a txt file contains the beginning time, ending time, minimum frequency, and maximum frequency of each detected call. Explore the detection result in Raven software."
      ],
      "metadata": {
        "id": "pgcXp5jTKGqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soundscape_mapper.soundscape_viewer import spectrogram_detection\n",
        "\n",
        "# Choose the source for signal detection\n",
        "source_num = 1\n",
        "    \n",
        "# Define the detection parameters\n",
        "sp=spectrogram_detection(model.separation[source_num-1], model.f, threshold=5.5, smooth=1, minimum_interval=0.5, \n",
        "                           filename='wind_detection.txt', path='./data/txt/')"
      ],
      "metadata": {
        "id": "UwvsZCp7KTSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}